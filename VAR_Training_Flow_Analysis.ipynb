{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VAR模型完整训练流程分析\n",
        "\n",
        "从命令行开始，详细分析VAR模型的训练流程，包括各个模块的调用关系和输入输出。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 命令行启动流程\n",
        "\n",
        "### 命令行参数解析\n",
        "```bash\n",
        "torchrun --nproc_per_node=8 --nnodes=... --node_rank=... --master_addr=... --master_port=... train.py \\\n",
        "  --depth=16 --bs=768 --ep=200 --fp16=1 --alng=1e-3 --wpe=0.1\n",
        "```\n",
        "\n",
        "**关键参数说明：**\n",
        "- `--depth=16`: VAR模型深度\n",
        "- `--bs=768`: 全局批次大小\n",
        "- `--ep=200`: 训练轮数\n",
        "- `--fp16=1`: 使用半精度训练\n",
        "- `--alng=1e-3`: AdaLN gamma初始化参数\n",
        "- `--wpe=0.1`: 学习率调度器最终比例\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 训练流程调用链\n",
        "\n",
        "### 2.1 入口点：`train.py` → `main_training()`\n",
        "\n",
        "**文件**: `train.py`\n",
        "**函数**: `main_training()`\n",
        "**输入**: 命令行参数\n",
        "**输出**: 训练完成\n",
        "\n",
        "**调用链**:\n",
        "1. `arg_util.init_dist_and_get_args()` - 初始化分布式训练和解析参数\n",
        "2. `build_everything(args)` - 构建所有组件\n",
        "3. 训练循环\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 参数解析：`utils/arg_util.py`\n",
        "\n",
        "**文件**: `utils/arg_util.py`\n",
        "**类**: `Args`\n",
        "**功能**: 解析命令行参数，设置默认值\n",
        "\n",
        "**关键参数处理**:\n",
        "```python\n",
        "# 批次大小计算\n",
        "bs_per_gpu = round(args.bs / args.ac / dist.get_world_size())\n",
        "args.batch_size = bs_per_gpu\n",
        "args.glb_batch_size = args.batch_size * dist.get_world_size()\n",
        "\n",
        "# 学习率计算\n",
        "args.tlr = args.ac * args.tblr * args.glb_batch_size / 256\n",
        "\n",
        "# Patch配置\n",
        "args.patch_nums = tuple(map(int, args.pn.replace('-', '_').split('_')))\n",
        "args.resos = tuple(pn * args.patch_size for pn in args.patch_nums)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 组件构建：`build_everything()`\n",
        "\n",
        "**文件**: `train.py`\n",
        "**函数**: `build_everything(args)`\n",
        "**输入**: 解析后的参数\n",
        "**输出**: 所有训练组件\n",
        "\n",
        "**构建流程**:\n",
        "1. **数据加载器构建**\n",
        "2. **模型构建**\n",
        "3. **优化器构建**\n",
        "4. **训练器构建**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 数据加载流程\n",
        "\n",
        "### 3.1 数据集构建：`utils/data.py`\n",
        "\n",
        "**文件**: `utils/data.py`\n",
        "**函数**: `build_dataset()`\n",
        "**输入**: 数据路径、分辨率、增强参数\n",
        "**输出**: 训练集、验证集、类别数\n",
        "\n",
        "**数据预处理流程**:\n",
        "```python\n",
        "# 训练集增强\n",
        "train_aug = [\n",
        "    transforms.Resize(mid_reso, interpolation=InterpolationMode.LANCZOS),\n",
        "    transforms.RandomCrop((final_reso, final_reso)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize_01_into_pm1,  # 归一化到[-1, 1]\n",
        "]\n",
        "\n",
        "# 验证集增强\n",
        "val_aug = [\n",
        "    transforms.Resize(mid_reso, interpolation=InterpolationMode.LANCZOS),\n",
        "    transforms.CenterCrop((final_reso, final_reso)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize_01_into_pm1,\n",
        "]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 数据加载器：`utils/data_sampler.py`\n",
        "\n",
        "**文件**: `utils/data_sampler.py`\n",
        "**类**: `DistInfiniteBatchSampler`\n",
        "**功能**: 分布式无限批次采样\n",
        "\n",
        "**数据流**:\n",
        "```python\n",
        "# 训练数据加载器\n",
        "ld_train = DataLoader(\n",
        "    dataset=dataset_train,\n",
        "    num_workers=args.workers,\n",
        "    pin_memory=True,\n",
        "    batch_sampler=DistInfiniteBatchSampler(\n",
        "        dataset_len=len(dataset_train),\n",
        "        glb_batch_size=args.glb_batch_size,\n",
        "        shuffle=True,\n",
        "        rank=dist.get_rank(),\n",
        "        world_size=dist.get_world_size(),\n",
        "    ),\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 模型构建流程\n",
        "\n",
        "### 4.1 VAE模型构建：`models/vqvae.py`\n",
        "\n",
        "**文件**: `models/vqvae.py`\n",
        "**类**: `VQVAE`\n",
        "**输入**: 图像 (B, 3, H, W)\n",
        "**输出**: 重建图像 (B, 3, H, W)\n",
        "\n",
        "**VAE组件**:\n",
        "```python\n",
        "class VQVAE(nn.Module):\n",
        "    def __init__(self, vocab_size=4096, z_channels=32, ch=128, ...):\n",
        "        self.encoder = Encoder(...)      # 编码器\n",
        "        self.decoder = Decoder(...)      # 解码器\n",
        "        self.quantize = VectorQuantizer2(...)  # 量化器\n",
        "        self.quant_conv = nn.Conv2d(...)       # 量化前卷积\n",
        "        self.post_quant_conv = nn.Conv2d(...)  # 量化后卷积\n",
        "```\n",
        "\n",
        "**关键方法**:\n",
        "- `img_to_idxBl()`: 图像 → Token序列\n",
        "- `idxBl_to_img()`: Token序列 → 图像\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 量化器：`models/quant.py`\n",
        "\n",
        "**文件**: `models/quant.py`\n",
        "**类**: `VectorQuantizer2`\n",
        "**功能**: 图像特征到离散Token的转换\n",
        "\n",
        "**量化流程**:\n",
        "```python\n",
        "class VectorQuantizer2(nn.Module):\n",
        "    def __init__(self, vocab_size, Cvae, using_znorm, beta=0.25, ...):\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.Cvae)  # 词汇表\n",
        "        self.quant_resi = Phi(...)  # 残差量化器\n",
        "        \n",
        "    def forward(self, f_BChw):\n",
        "        # 多尺度量化\n",
        "        for si, pn in enumerate(self.v_patch_nums):\n",
        "            # 1. 插值到目标尺寸\n",
        "            rest_NC = F.interpolate(f_rest, size=(pn, pn), mode='area')\n",
        "            # 2. 找到最近邻嵌入\n",
        "            idx_N = torch.argmin(distance, dim=1)\n",
        "            # 3. 获取量化特征\n",
        "            h_BChw = self.embedding(idx_Bhw)\n",
        "            # 4. 残差更新\n",
        "            f_hat += h_BChw\n",
        "            f_rest -= h_BChw\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 VAR模型构建：`models/var.py`\n",
        "\n",
        "**文件**: `models/var.py`\n",
        "**类**: `VAR`\n",
        "**输入**: 标签 (B,), Token序列 (B, L, Cvae)\n",
        "**输出**: 预测logits (B, L, V)\n",
        "\n",
        "**VAR组件**:\n",
        "```python\n",
        "class VAR(nn.Module):\n",
        "    def __init__(self, vae_local, num_classes=1000, depth=16, ...):\n",
        "        # 1. 词嵌入层\n",
        "        self.word_embed = nn.Linear(self.Cvae, self.C)\n",
        "        \n",
        "        # 2. 类别嵌入\n",
        "        self.class_emb = nn.Embedding(self.num_classes + 1, self.C)\n",
        "        \n",
        "        # 3. 位置嵌入\n",
        "        self.pos_1LC = nn.Parameter(...)\n",
        "        self.lvl_embed = nn.Embedding(len(self.patch_nums), self.C)\n",
        "        \n",
        "        # 4. Transformer块\n",
        "        self.blocks = nn.ModuleList([AdaLNSelfAttn(...) for _ in range(depth)])\n",
        "        \n",
        "        # 5. 分类头\n",
        "        self.head = nn.Linear(self.C, self.V)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 训练流程\n",
        "\n",
        "### 5.1 训练器：`trainer.py`\n",
        "\n",
        "**文件**: `trainer.py`\n",
        "**类**: `VARTrainer`\n",
        "**功能**: 管理训练过程\n",
        "\n",
        "**训练步骤**:\n",
        "```python\n",
        "def train_step(self, inp_B3HW, label_B, ...):\n",
        "    # 1. 图像 → Token\n",
        "    gt_idx_Bl = self.vae_local.img_to_idxBl(inp_B3HW)\n",
        "    gt_BL = torch.cat(gt_idx_Bl, dim=1)\n",
        "    \n",
        "    # 2. Token → VAR输入\n",
        "    x_BLCv_wo_first_l = self.quantize_local.idxBl_to_var_input(gt_idx_Bl)\n",
        "    \n",
        "    # 3. VAR前向传播\n",
        "    logits_BLV = self.var(label_B, x_BLCv_wo_first_l)\n",
        "    \n",
        "    # 4. 计算损失\n",
        "    loss = self.train_loss(logits_BLV.view(-1, V), gt_BL.view(-1))\n",
        "    \n",
        "    # 5. 反向传播\n",
        "    grad_norm, scale_log2 = self.var_opt.backward_clip_step(loss=loss)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 训练循环：`train.py`\n",
        "\n",
        "**文件**: `train.py`\n",
        "**函数**: `train_one_ep()`\n",
        "**功能**: 单轮训练\n",
        "\n",
        "**训练循环**:\n",
        "```python\n",
        "for ep in range(start_ep, args.ep):\n",
        "    for it, (inp, label) in enumerate(ld_train):\n",
        "        # 1. 数据预处理\n",
        "        inp = inp.to(device, non_blocking=True)\n",
        "        label = label.to(device, non_blocking=True)\n",
        "        \n",
        "        # 2. 学习率调度\n",
        "        min_tlr, max_tlr = lr_wd_annealing(...)\n",
        "        \n",
        "        # 3. 渐进训练\n",
        "        if args.pg:\n",
        "            prog_si = calculate_progressive_stage(g_it, wp_it, max_it)\n",
        "        \n",
        "        # 4. 训练步骤\n",
        "        grad_norm, scale_log2 = trainer.train_step(\n",
        "            inp_B3HW=inp, label_B=label, prog_si=prog_si, ...\n",
        "        )\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 关键数据流转换\n",
        "\n",
        "### 6.1 图像到Token转换\n",
        "\n",
        "```python\n",
        "# 输入: 图像 (B, 3, H, W)\n",
        "inp_B3HW = torch.randn(B, 3, 256, 256)\n",
        "\n",
        "# 1. VAE编码\n",
        "f_BChw = vae.quant_conv(vae.encoder(inp_B3HW))  # (B, 32, 16, 16)\n",
        "\n",
        "# 2. 多尺度量化\n",
        "gt_idx_Bl = vae.img_to_idxBl(inp_B3HW)  # List[Tensor]\n",
        "# 结果: [\n",
        "#   Tensor(B, 1),    # 1x1 patch\n",
        "#   Tensor(B, 4),    # 2x2 patch\n",
        "#   Tensor(B, 9),    # 3x3 patch\n",
        "#   ...\n",
        "#   Tensor(B, 256),  # 16x16 patch\n",
        "# ]\n",
        "\n",
        "# 3. 拼接为序列\n",
        "gt_BL = torch.cat(gt_idx_Bl, dim=1)  # (B, L) where L = sum(pn^2)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Token到VAR输入转换\n",
        "\n",
        "```python\n",
        "# 输入: Token序列 List[Tensor]\n",
        "gt_idx_Bl = [Tensor(B, 1), Tensor(B, 4), ..., Tensor(B, 256)]\n",
        "\n",
        "# 1. 转换为VAR输入\n",
        "x_BLCv_wo_first_l = quantize.idxBl_to_var_input(gt_idx_Bl)\n",
        "# 结果: (B, L-1, 32) - 去掉第一个token\n",
        "\n",
        "# 2. VAR前向传播\n",
        "logits_BLV = var(label_B, x_BLCv_wo_first_l)\n",
        "# 结果: (B, L, 4096) - 预测每个位置的token\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 损失计算\n",
        "\n",
        "```python\n",
        "# 1. 计算交叉熵损失\n",
        "loss = CrossEntropyLoss(logits_BLV.view(-1, V), gt_BL.view(-1))\n",
        "\n",
        "# 2. 渐进训练权重\n",
        "if prog_si >= 0:\n",
        "    bg, ed = begin_ends[prog_si]\n",
        "    lw = loss_weight[:, :ed].clone()\n",
        "    lw[:, bg:ed] *= prog_wp  # 渐进权重\n",
        "\n",
        "# 3. 加权损失\n",
        "loss = loss.mul(lw).sum(dim=-1).mean()\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 关键文件总结\n",
        "\n",
        "| 文件 | 主要功能 | 关键类/函数 | 输入 | 输出 |\n",
        "|------|----------|-------------|------|------|\n",
        "| `train.py` | 训练入口 | `main_training()` | 命令行参数 | 训练完成 |\n",
        "| `utils/arg_util.py` | 参数解析 | `Args` | 命令行 | 解析后参数 |\n",
        "| `utils/data.py` | 数据加载 | `build_dataset()` | 数据路径 | 数据集 |\n",
        "| `models/vqvae.py` | VAE模型 | `VQVAE` | 图像 | 重建图像 |\n",
        "| `models/quant.py` | 量化器 | `VectorQuantizer2` | 特征 | Token |\n",
        "| `models/var.py` | VAR模型 | `VAR` | Token+标签 | 预测logits |\n",
        "| `trainer.py` | 训练器 | `VARTrainer` | 数据+模型 | 训练步骤 |\n",
        "| `utils/amp_sc.py` | 优化器 | `AmpOptimizer` | 损失 | 梯度更新 |\n",
        "| `utils/lr_control.py` | 学习率调度 | `lr_wd_annealing()` | 当前步数 | 学习率 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 训练流程总结\n",
        "\n",
        "1. **初始化**: 解析参数 → 初始化分布式 → 设置环境\n",
        "2. **数据准备**: 构建数据集 → 创建数据加载器\n",
        "3. **模型构建**: VAE → 量化器 → VAR → 优化器\n",
        "4. **训练循环**: 数据加载 → 前向传播 → 损失计算 → 反向传播 → 参数更新\n",
        "5. **评估保存**: 验证集评估 → 模型保存 → 日志记录\n",
        "\n",
        "整个训练流程通过模块化设计，实现了从原始图像到离散Token的转换，再到自回归预测的完整pipeline。\n",
        "\n",
        "**关键数据流**:\n",
        "- 图像 (B,3,H,W) → VAE编码 → 特征 (B,32,H/16,W/16) → 量化器 → Token序列 → VAR模型 → 预测logits → 损失计算 → 反向传播\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
